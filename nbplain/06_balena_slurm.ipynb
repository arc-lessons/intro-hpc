{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accessing software on Balena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview:\n",
    "- **Teaching:** 10 min\n",
    "- **Exercises:** 5 min\n",
    "\n",
    "**Questions**\n",
    "- What is a scheduler?\n",
    "- How can I use `slurm` to manage and run my jobs?\n",
    "- What `slurm` commands can I use to explore Balena?\n",
    "- How I do I access information about my project accounts?\n",
    "\n",
    "**Objectives**\n",
    "- Know that the schduler manages jobs on the service\n",
    "- Know how to interact with `slurm` to:\n",
    "  - See what jobs are running\n",
    "  - Check availability of different partitions\n",
    "  - Check how much resource you have available in your projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scheduler\n",
    "\n",
    "Unlike your desktop or perhaps a group server Balena is a shared resource accessible to all reasearchers in the University.  As such we need to manage how jobs are run to ensure that everyone gets to run `fair share` and that resources are used efficiently.\n",
    "\n",
    "If multiple jobs ran on a single `node` at the same time users would be cometing for the same resources and jobs take longer to run overall.  By managing jobs through the scheduler individual jobs are allocated to the resources they need as they become available.  This results in a higher overall throughput and more consistent perforamnce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Slurm: **S**imple **L**inux **U**tility for **R**esource **M**anagement\n",
    "\n",
    "The are a number of scheduler's in use in HPC systems, on Balena we use `slurm`.  In order to interact with the scheduler you need to be familiar with a number of key `slurm` commands:\n",
    "\n",
    "| Slurm command | Function |\n",
    "|---|---|\n",
    "| `sinfo` | View information about SLURM nodes and partitions |\n",
    "| `squeue` | List status of jobs in the **queue** |\n",
    "| squeue --user [userid] | Jobs by user |\n",
    "| squeue --job [jobid] | Jobs by jobid |\n",
    "| sbatch [jobscript] | Submit a jobscript to the scheduler |\n",
    "| scancel [jobid] | Cancel a job in the queue |\n",
    "| sshare | Show project and fairshare information |\n",
    "| scontrol hold [jobid] | Hold a job in the queue |\n",
    "| scontrol release [jobid] | Release a held job |\n",
    "| scontrol show job [jobid] | View information about a job |\n",
    "| scontrol show node nodename | Get information of a node |\n",
    "| scontrol show license | Get licenses available on SLURM |\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%bash2` not found.\n"
     ]
    }
   ],
   "source": [
    "%%bash2\n",
    "sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each of these partitions have inrmative names that explain what each contains. The `batch-acc` is used for all the nodes that have acelerators or off loading devices.  We can find out more about these with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%bash2\n",
    "sinfo Ne1 --partition batch-acc --format=nodelist,features,gres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%bash2\n",
    "sshare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Key Points:\n",
    "- We use a scheduler to manage jobs on the HPC service, ensuring fair share and efficient use.\n",
    "- Balena uses the `slurm` scheduler\n",
    "- Key commands are:\n",
    "  * `sbatch` to submit a job\n",
    "  * `sinfo` to view information about the servive\n",
    "  * `scancel` to delete a job\n",
    "  * `squeue` to view the queue"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
